{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import to_tensor, normalize\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import Food101\n",
    "from torchvision import datasets, transforms\n",
    "import statistics as st\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "def test_acc(net: nn.Module, test_loader: DataLoader):\n",
    "\n",
    "  net.to(device)\n",
    "  net.eval()\n",
    "  \n",
    "  total = 0\n",
    "  correct = 0\n",
    "\n",
    "  for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    total += labels.size(0)\n",
    "\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "  return correct / total * 100\n",
    "\n",
    "def train_fn(epochs: int, train_loader: DataLoader,\n",
    "             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer, train_dataset_length):\n",
    "\n",
    "  # losses = []\n",
    "  # accuracies = []\n",
    "\n",
    "  net.to(device)\n",
    "\n",
    "  for e in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "      images, labels = images.to(device), labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(images)\n",
    "      loss = loss_fn(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / train_dataset_length\n",
    "\n",
    "    print(f\"Loss: {epoch_loss}\")\n",
    "\n",
    "    # acc = test_acc(net, test_loader)\n",
    "    # print(f\"Acuratetea la finalul epocii {e + 1} este {acc:.2f}%\")\n",
    "\n",
    "    # losses.append(epoch_loss)\n",
    "    # accuracies.append(acc)\n",
    "\n",
    "    # torch.save(net.state_dict(), f'resnet50_multiplefclayers_adamw_epoch{e + 1}.pkl')\n",
    "\n",
    "  # loss_graph(losses)\n",
    "  # accuracy_graph(accuracies)\n",
    "\n",
    "def loss_graph(losses):\n",
    "    plt.plot(losses)\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "\n",
    "def accuracy_graph(accuracies):\n",
    "    plt.plot(accuracies)\n",
    "\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n",
    "\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomClassifier, self).__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 101)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vlad Talpiga.VLR_PROJAMZ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vlad Talpiga.VLR_PROJAMZ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split 1\n",
      "Loss: 3.0810552119264507\n",
      "Accuracy: 48.24%\n",
      "Duration of training: 12.978929408391316\n",
      "Training split 2\n",
      "Loss: 3.068732658518423\n",
      "Accuracy: 47.69%\n",
      "Duration of training: 12.902049148082734\n",
      "Training split 3\n",
      "Loss: 3.0849373537951177\n",
      "Accuracy: 47.09%\n",
      "Duration of training: 12.216011277834575\n",
      "Training split 4\n",
      "Loss: 3.076727840404699\n",
      "Accuracy: 48.29%\n",
      "Duration of training: 12.372770484288534\n",
      "Training split 5\n",
      "Loss: 3.0747044070404357\n",
      "Accuracy: 47.27%\n",
      "Duration of training: 11.904874269167582\n",
      "[48.23762376237624, 47.68811881188119, 47.089108910891085, 48.28712871287129, 47.27227722772277]\n",
      "47.714851485148515\n",
      "Config 2:\n",
      "Training split 1\n",
      "Loss: 3.0778460174031776\n",
      "Accuracy: 47.93%\n",
      "Duration of training: 12.07348201672236\n",
      "Training split 2\n",
      "Loss: 3.0628571816246106\n",
      "Accuracy: 47.51%\n",
      "Duration of training: 12.030071485042573\n",
      "Training split 3\n",
      "Loss: 3.0777367574861736\n",
      "Accuracy: 47.44%\n",
      "Duration of training: 11.881509733200073\n",
      "Training split 4\n",
      "Loss: 3.0871829512567803\n",
      "Accuracy: 48.14%\n",
      "Duration of training: 11.850429157416025\n",
      "Training split 5\n",
      "Loss: 3.065572895201126\n",
      "Accuracy: 47.03%\n",
      "Duration of training: 11.88696157137553\n",
      "[47.92574257425743, 47.51485148514851, 47.44059405940594, 48.14356435643564, 47.02970297029702]\n",
      "47.61089108910891\n",
      "Config 3:\n",
      "Training split 1\n",
      "Loss: 3.06485158504826\n",
      "Accuracy: 48.29%\n",
      "Duration of training: 11.986088252067566\n",
      "Training split 2\n",
      "Loss: 3.081304767438681\n",
      "Accuracy: 47.40%\n",
      "Duration of training: 13.535279552141825\n",
      "Training split 3\n",
      "Loss: 3.0823568087285107\n",
      "Accuracy: 47.37%\n",
      "Duration of training: 12.251812926928203\n",
      "Training split 4\n",
      "Loss: 3.07724681202728\n",
      "Accuracy: 48.29%\n",
      "Duration of training: 12.258127756913503\n",
      "Training split 5\n",
      "Loss: 3.0606742228139745\n",
      "Accuracy: 47.37%\n",
      "Duration of training: 12.515656061967213\n",
      "[48.29207920792079, 47.396039603960396, 47.366336633663366, 48.28712871287129, 47.37128712871287]\n",
      "47.742574257425744\n",
      "Config 4:\n",
      "Training split 1\n",
      "Loss: 2.7675164581525444\n",
      "Accuracy: 51.48%\n",
      "Duration of training: 11.845408256848653\n",
      "Training split 2\n",
      "Loss: 2.7816254466595036\n",
      "Accuracy: 50.65%\n",
      "Duration of training: 12.732482365767162\n",
      "Training split 3\n",
      "Loss: 2.767895347104214\n",
      "Accuracy: 50.22%\n",
      "Duration of training: 13.120561254024505\n",
      "Training split 4\n",
      "Loss: 2.7893102985325426\n",
      "Accuracy: 50.87%\n",
      "Duration of training: 13.21383893887202\n",
      "Training split 5\n",
      "Loss: 2.7649715553888\n",
      "Accuracy: 50.18%\n",
      "Duration of training: 12.248790645599366\n",
      "[51.475247524752476, 50.648514851485146, 50.21782178217822, 50.87128712871287, 50.18316831683168]\n",
      "50.67920792079208\n",
      "Config 5:\n",
      "Training split 1\n",
      "Loss: 2.771152008736488\n",
      "Accuracy: 50.85%\n",
      "Duration of training: 11.927028028170268\n",
      "Training split 2\n",
      "Loss: 2.7446784095008776\n",
      "Accuracy: 50.63%\n",
      "Duration of training: 12.369761661688488\n",
      "Training split 3\n",
      "Loss: 2.7548279586640914\n",
      "Accuracy: 50.35%\n",
      "Duration of training: 12.252149919668833\n",
      "Training split 4\n",
      "Loss: 2.771364165391072\n",
      "Accuracy: 51.12%\n",
      "Duration of training: 12.079634042580922\n",
      "Training split 5\n",
      "Loss: 2.748130718174547\n",
      "Accuracy: 50.33%\n",
      "Duration of training: 11.963907233874004\n",
      "[50.84653465346535, 50.62871287128713, 50.34653465346535, 51.12376237623762, 50.32673267326733]\n",
      "50.654455445544556\n",
      "Config 6:\n",
      "Training split 1\n",
      "Loss: 2.762166075564847\n",
      "Accuracy: 51.20%\n",
      "Duration of training: 11.971327654520671\n",
      "Training split 2\n",
      "Loss: 2.7576949975986293\n",
      "Accuracy: 50.47%\n",
      "Duration of training: 12.060034124056498\n",
      "Training split 3\n",
      "Loss: 2.7576580489507996\n",
      "Accuracy: 50.35%\n",
      "Duration of training: 12.100866297880808\n",
      "Training split 4\n",
      "Loss: 2.766192906351373\n",
      "Accuracy: 51.07%\n",
      "Duration of training: 12.178604940573374\n",
      "Training split 5\n",
      "Loss: 2.7540427305202675\n",
      "Accuracy: 50.67%\n",
      "Duration of training: 11.735756961504618\n",
      "[51.2029702970297, 50.47029702970297, 50.351485148514854, 51.07425742574257, 50.67326732673267]\n",
      "50.75445544554455\n",
      "Config 7:\n",
      "Training split 1\n",
      "Loss: 2.47508248045893\n",
      "Accuracy: 51.95%\n",
      "Duration of training: 11.785702971617381\n",
      "Training split 2\n",
      "Loss: 2.4733975635188643\n",
      "Accuracy: 50.98%\n",
      "Duration of training: 12.051820651690166\n",
      "Training split 3\n",
      "Loss: 2.4675959800965717\n",
      "Accuracy: 51.06%\n",
      "Duration of training: 11.910736278692882\n",
      "Training split 4\n",
      "Loss: 2.479220716929672\n",
      "Accuracy: 51.87%\n",
      "Duration of training: 11.995696850617726\n",
      "Training split 5\n",
      "Loss: 2.459489980640978\n",
      "Accuracy: 50.90%\n",
      "Duration of training: 11.683460839589436\n",
      "[51.95049504950495, 50.98019801980198, 51.06435643564357, 51.87128712871287, 50.9009900990099]\n",
      "51.353465346534655\n",
      "Config 8:\n",
      "Training split 1\n",
      "Loss: 2.4655829776159606\n",
      "Accuracy: 51.40%\n",
      "Duration of training: 11.623594506581624\n",
      "Training split 2\n",
      "Loss: 2.473975332939979\n",
      "Accuracy: 50.90%\n",
      "Duration of training: 11.848938385645548\n",
      "Training split 3\n",
      "Loss: 2.453136233244792\n",
      "Accuracy: 51.80%\n",
      "Duration of training: 11.79307987689972\n",
      "Training split 4\n",
      "Loss: 2.4808963729367397\n",
      "Accuracy: 52.60%\n",
      "Duration of training: 11.98672597805659\n",
      "Training split 5\n",
      "Loss: 2.458544560139722\n",
      "Accuracy: 51.01%\n",
      "Duration of training: 11.612574287255605\n",
      "[51.4009900990099, 50.896039603960396, 51.801980198019805, 52.603960396039604, 51.00990099009901]\n",
      "51.54257425742574\n",
      "Config 9:\n",
      "Training split 1\n",
      "Loss: 2.4787558832735117\n",
      "Accuracy: 51.52%\n",
      "Duration of training: 11.582552107175191\n",
      "Training split 2\n",
      "Loss: 2.4681717003926193\n",
      "Accuracy: 50.89%\n",
      "Duration of training: 11.460917361577351\n",
      "Training split 3\n",
      "Loss: 2.4754418400490636\n",
      "Accuracy: 51.13%\n",
      "Duration of training: 11.473238321145375\n",
      "Training split 4\n",
      "Loss: 2.469621633019778\n",
      "Accuracy: 51.87%\n",
      "Duration of training: 11.578379344940185\n",
      "Training split 5\n",
      "Loss: 2.4611761496798827\n",
      "Accuracy: 50.80%\n",
      "Duration of training: 8.4860933025678\n",
      "[51.524752475247524, 50.89108910891089, 51.133663366336634, 51.87128712871287, 50.801980198019805]\n",
      "51.244554455445545\n",
      "[47.714851485148515, 47.61089108910891, 47.742574257425744, 50.67920792079208, 50.654455445544556, 50.75445544554455, 51.353465346534655, 51.54257425742574, 51.244554455445545]\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "\n",
    "configs = [(0.9, 0.001), (0.9, 0.0001), (0.9, 0.00001), (0.95, 0.001), (0.95, 0.0001), (0.95, 0.00001), (0.99, 0.001), (0.99, 0.0001), (0.99, 0.00001)]\n",
    "mean_accuracies = []\n",
    "i = 1\n",
    "\n",
    "for momentum, weight_decay in configs:\n",
    "\n",
    "    print(f'Config {i}:')\n",
    "    i += 1\n",
    "    accuracies = []\n",
    "\n",
    "    for split_number in range(1, 6):\n",
    "\n",
    "        train_dir = f\"C:/Users/Vlad Talpiga.VLR_PROJAMZ/OneDrive - Valrom Industrie SRL/Desktop/IAVA/Proiect/FoodClassifier/cross_validation/dataset/split{split_number}/train\"\n",
    "        val_dir = f\"C:/Users/Vlad Talpiga.VLR_PROJAMZ/OneDrive - Valrom Industrie SRL/Desktop/IAVA/Proiect/FoodClassifier/cross_validation/dataset/split{split_number}/validation\"\n",
    "    \n",
    "        train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        # Freeze all layers except the final classification layer\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        resnet = nn.Sequential(\n",
    "            resnet,\n",
    "            CustomClassifier()\n",
    "        )\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Training split {split_number}')\n",
    "\n",
    "        train_fn(1, train_loader, resnet, loss_fn, optimizer, len(train_dataset))\n",
    "\n",
    "        acc = test_acc(resnet, val_loader)\n",
    "\n",
    "        print(f'Accuracy: {acc:.2f}%')\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        end = time.time()\n",
    "        print(f'Duration of training: {(end - start) / 60}')\n",
    "\n",
    "    mean_accuracies.append(st.mean(accuracies))\n",
    "    \n",
    "    print(accuracies)\n",
    "    print(st.mean(accuracies))\n",
    "\n",
    "print(mean_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vlad Talpiga.VLR_PROJAMZ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vlad Talpiga.VLR_PROJAMZ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split 1\n",
      "Loss: 2.3789230561492465\n",
      "Accuracy: 52.08%\n",
      "Duration of training: 16.35149817466736\n",
      "Training split 2\n",
      "Loss: 2.3709249138596036\n",
      "Accuracy: 51.59%\n",
      "Duration of training: 15.881305054823558\n",
      "Training split 3\n",
      "Loss: 2.3662334962410503\n",
      "Accuracy: 51.42%\n",
      "Duration of training: 15.982991123199463\n",
      "Training split 4\n",
      "Loss: 2.384864184502328\n",
      "Accuracy: 51.32%\n",
      "Duration of training: 15.936261602242787\n",
      "Training split 5\n",
      "Loss: 2.3707797448941976\n",
      "Accuracy: 50.00%\n",
      "Duration of training: 122.5415296514829\n",
      "[52.07920792079208, 51.58910891089109, 51.415841584158414, 51.32178217821782, 50.0]\n",
      "51.28118811881188\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for split_number in range(1, 6):\n",
    "\n",
    "    train_dir = f\"C:/Users/Vlad Talpiga.VLR_PROJAMZ/OneDrive - Valrom Industrie SRL/Desktop/IAVA/Proiect/FoodClassifier/cross_validation/dataset/split{split_number}/train\"\n",
    "    val_dir = f\"C:/Users/Vlad Talpiga.VLR_PROJAMZ/OneDrive - Valrom Industrie SRL/Desktop/IAVA/Proiect/FoodClassifier/cross_validation/dataset/split{split_number}/validation\"\n",
    " \n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "    # Freeze all layers except the final classification layer\n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    resnet = nn.Sequential(\n",
    "        resnet,\n",
    "        CustomClassifier()\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(resnet.parameters(), lr=0.0009)\n",
    "\n",
    "    start = time.time()\n",
    "    print(f'Training split {split_number}')\n",
    "\n",
    "    train_fn(1, train_loader, resnet, loss_fn, optimizer, len(train_dataset))\n",
    "\n",
    "    acc = test_acc(resnet, val_loader)\n",
    "\n",
    "    print(f'Accuracy: {acc:.2f}%')\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'Duration of training: {(end - start) / 60}')\n",
    "\n",
    "print(accuracies)\n",
    "print(st.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 1:\n",
      "Training split 1\n",
      "Loss: 2.3691504467123807\n",
      "Accuracy: 52.10%\n",
      "Duration of training: 8.628341674804688\n",
      "Training split 2\n",
      "Loss: 2.3708721514975672\n",
      "Accuracy: 50.81%\n",
      "Duration of training: 8.635489885012309\n",
      "Training split 3\n",
      "Loss: 2.362696132943182\n",
      "Accuracy: 51.02%\n",
      "Duration of training: 8.632052675882976\n",
      "Training split 4\n",
      "Loss: 2.365888430246032\n",
      "Accuracy: 52.20%\n",
      "Duration of training: 8.63960640033086\n",
      "Training split 5\n",
      "Loss: 2.3532089421300606\n",
      "Accuracy: 50.35%\n",
      "Duration of training: 8.631850492954253\n",
      "[52.0990099009901, 50.806930693069305, 51.024752475247524, 52.1980198019802, 50.34653465346535]\n",
      "51.2950495049505\n",
      "Config 2:\n",
      "Training split 1\n",
      "Loss: 2.359435354317769\n",
      "Accuracy: 52.14%\n",
      "Duration of training: 8.645898675918579\n",
      "Training split 2\n",
      "Loss: 2.361776711208986\n",
      "Accuracy: 50.94%\n",
      "Duration of training: 8.63192676305771\n",
      "Training split 3\n",
      "Loss: 2.365243058582344\n",
      "Accuracy: 52.07%\n",
      "Duration of training: 8.6666472752889\n",
      "Training split 4\n",
      "Loss: 2.3650460994833766\n",
      "Accuracy: 52.17%\n",
      "Duration of training: 8.63065318663915\n",
      "Training split 5\n",
      "Loss: 2.355391670075974\n",
      "Accuracy: 50.86%\n",
      "Duration of training: 8.664199928442637\n",
      "[52.14356435643565, 50.94059405940594, 52.069306930693074, 52.17326732673268, 50.86138613861386]\n",
      "51.637623762376236\n",
      "Config 3:\n",
      "Training split 1\n",
      "Loss: 2.37506379793186\n",
      "Accuracy: 51.53%\n",
      "Duration of training: 8.62781601746877\n",
      "Training split 2\n",
      "Loss: 2.3666202862427967\n",
      "Accuracy: 50.93%\n",
      "Duration of training: 8.641679040590923\n",
      "Training split 3\n",
      "Loss: 2.3621599537311213\n",
      "Accuracy: 51.18%\n",
      "Duration of training: 8.625246584415436\n",
      "Training split 4\n",
      "Loss: 2.377884942422999\n",
      "Accuracy: 52.46%\n",
      "Duration of training: 8.63803153038025\n",
      "Training split 5\n",
      "Loss: 2.356714068120069\n",
      "Accuracy: 50.76%\n",
      "Duration of training: 8.631556089719137\n",
      "[51.52970297029703, 50.92574257425743, 51.17821782178218, 52.460396039603964, 50.757425742574256]\n",
      "51.37029702970297\n",
      "Config 4:\n",
      "Training split 1\n",
      "Loss: 2.3660623117012554\n",
      "Accuracy: 52.26%\n",
      "Duration of training: 8.654165554046632\n",
      "Training split 2\n",
      "Loss: 2.364877592030138\n",
      "Accuracy: 51.34%\n",
      "Duration of training: 8.637448569138845\n",
      "Training split 3\n",
      "Loss: 2.365246653131919\n",
      "Accuracy: 51.71%\n",
      "Duration of training: 8.644940133889516\n",
      "Training split 4\n",
      "Loss: 2.3739526970551745\n",
      "Accuracy: 52.82%\n",
      "Duration of training: 8.62811940908432\n",
      "Training split 5\n",
      "Loss: 2.367862814015681\n",
      "Accuracy: 50.36%\n",
      "Duration of training: 8.994985806941987\n",
      "[52.26237623762376, 51.336633663366335, 51.71287128712871, 52.82178217821782, 50.35643564356435]\n",
      "51.698019801980195\n",
      "Config 5:\n",
      "Training split 1\n",
      "Loss: 2.366748808398105\n",
      "Accuracy: 51.48%\n",
      "Duration of training: 9.356817217667897\n",
      "Training split 2\n",
      "Loss: 2.3647986153328775\n",
      "Accuracy: 52.14%\n",
      "Duration of training: 9.396572709083557\n",
      "Training split 3\n",
      "Loss: 2.365272053728009\n",
      "Accuracy: 50.80%\n",
      "Duration of training: 9.008264684677124\n",
      "Training split 4\n",
      "Loss: 2.37910933145202\n",
      "Accuracy: 52.90%\n",
      "Duration of training: 8.676723364988963\n",
      "Training split 5\n",
      "Loss: 2.3596004641882264\n",
      "Accuracy: 50.91%\n",
      "Duration of training: 8.769983653227488\n",
      "[51.475247524752476, 52.13861386138614, 50.801980198019805, 52.896039603960396, 50.90594059405941]\n",
      "51.64356435643565\n",
      "Config 6:\n",
      "Training split 1\n",
      "Loss: 2.360061729450037\n",
      "Accuracy: 51.79%\n",
      "Duration of training: 10.110887296994527\n",
      "Training split 2\n",
      "Loss: 2.368250248125284\n",
      "Accuracy: 51.52%\n",
      "Duration of training: 13.701503698031107\n",
      "Training split 3\n",
      "Loss: 2.3625300524494435\n",
      "Accuracy: 51.86%\n",
      "Duration of training: 12.711171249548594\n",
      "Training split 4\n",
      "Loss: 2.3741054844620204\n",
      "Accuracy: 53.13%\n",
      "Duration of training: 12.66845282316208\n",
      "Training split 5\n",
      "Loss: 2.359293534307197\n",
      "Accuracy: 51.36%\n",
      "Duration of training: 12.813343826929728\n",
      "[51.79207920792079, 51.524752475247524, 51.86138613861387, 53.128712871287135, 51.36138613861386]\n",
      "51.93366336633664\n",
      "Config 7:\n",
      "Training split 1\n",
      "Loss: 2.3707596130182247\n",
      "Accuracy: 51.82%\n",
      "Duration of training: 12.651033512751262\n",
      "Training split 2\n",
      "Loss: 2.3692822192919136\n",
      "Accuracy: 51.63%\n",
      "Duration of training: 12.788840663433074\n",
      "Training split 3\n",
      "Loss: 2.3642425835486685\n",
      "Accuracy: 50.57%\n",
      "Duration of training: 12.778700709342957\n",
      "Training split 4\n",
      "Loss: 2.3819853518268848\n",
      "Accuracy: 51.96%\n",
      "Duration of training: 12.65294178724289\n",
      "Training split 5\n",
      "Loss: 2.3621193711120303\n",
      "Accuracy: 49.78%\n",
      "Duration of training: 12.804059175650279\n",
      "[51.81683168316832, 51.633663366336634, 50.57425742574257, 51.960396039603964, 49.777227722772274]\n",
      "51.152475247524755\n",
      "Config 8:\n",
      "Training split 1\n",
      "Loss: 2.3683785725584126\n",
      "Accuracy: 51.56%\n",
      "Duration of training: 12.764633997281392\n",
      "Training split 2\n",
      "Loss: 2.363049467152888\n",
      "Accuracy: 51.32%\n",
      "Duration of training: 12.713249691327412\n",
      "Training split 3\n",
      "Loss: 2.363878788145462\n",
      "Accuracy: 50.95%\n",
      "Duration of training: 12.785712317625682\n",
      "Training split 4\n",
      "Loss: 2.374977654419323\n",
      "Accuracy: 52.02%\n",
      "Duration of training: 12.625034022331239\n",
      "Training split 5\n",
      "Loss: 2.36129658208035\n",
      "Accuracy: 48.93%\n",
      "Duration of training: 12.801838715871176\n",
      "[51.56435643564357, 51.31683168316832, 50.95049504950495, 52.024752475247524, 48.92574257425743]\n",
      "50.956435643564355\n",
      "Config 9:\n",
      "Training split 1\n",
      "Loss: 2.365783257153955\n",
      "Accuracy: 51.19%\n",
      "Duration of training: 12.748746347427367\n",
      "Training split 2\n",
      "Loss: 2.366695390078101\n",
      "Accuracy: 51.05%\n",
      "Duration of training: 12.672898602485656\n",
      "Training split 3\n",
      "Loss: 2.365033664325676\n",
      "Accuracy: 51.32%\n",
      "Duration of training: 12.754489946365357\n",
      "Training split 4\n",
      "Loss: 2.371289721149029\n",
      "Accuracy: 52.06%\n",
      "Duration of training: 12.673430411020915\n",
      "Training split 5\n",
      "Loss: 2.367627456778347\n",
      "Accuracy: 50.08%\n",
      "Duration of training: 12.741568283240001\n",
      "[51.18811881188119, 51.054455445544555, 51.31683168316832, 52.05940594059406, 50.07920792079208]\n",
      "51.13960396039604\n",
      "[51.2950495049505, 51.637623762376236, 51.37029702970297, 51.698019801980195, 51.64356435643565, 51.93366336633664, 51.152475247524755, 50.956435643564355, 51.13960396039604]\n"
     ]
    }
   ],
   "source": [
    "# AdamW\n",
    "\n",
    "configs = [(0.9, 0.999, 0.01), (0.9, 0.999, 0.001), (0.9, 0.999, 0.0001), (0.95, 0.999, 0.01), (0.95, 0.999, 0.001), (0.95, 0.999, 0.0001), (0.85, 0.999, 0.01), (0.85, 0.999, 0.001), (0.85, 0.999, 0.0001)]\n",
    "mean_accuracies = []\n",
    "i = 1\n",
    "\n",
    "for b1, b2, weight_decay in configs:\n",
    "\n",
    "    print(f'Config {i}:')\n",
    "    i += 1\n",
    "    accuracies = []\n",
    "\n",
    "    for split_number in range(1, 6):\n",
    "\n",
    "        train_dir = f\"C:/Users/Vlad Talpiga.VLR_PROJAMZ/OneDrive - Valrom Industrie SRL/Desktop/IAVA/Proiect/FoodClassifier/cross_validation/dataset/split{split_number}/train\"\n",
    "        val_dir = f\"C:/Users/Vlad Talpiga.VLR_PROJAMZ/OneDrive - Valrom Industrie SRL/Desktop/IAVA/Proiect/FoodClassifier/cross_validation/dataset/split{split_number}/validation\"\n",
    "    \n",
    "        train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        # Freeze all layers except the final classification layer\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        resnet = nn.Sequential(\n",
    "            resnet,\n",
    "            CustomClassifier()\n",
    "        )\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(resnet.parameters(), lr=0.001, betas=(b1, b2), weight_decay=weight_decay)\n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Training split {split_number}')\n",
    "\n",
    "        train_fn(1, train_loader, resnet, loss_fn, optimizer, len(train_dataset))\n",
    "\n",
    "        acc = test_acc(resnet, val_loader)\n",
    "\n",
    "        print(f'Accuracy: {acc:.2f}%')\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        end = time.time()\n",
    "        print(f'Duration of training: {(end - start) / 60}')\n",
    "\n",
    "    mean_accuracies.append(st.mean(accuracies))\n",
    "    \n",
    "    print(accuracies)\n",
    "    print(st.mean(accuracies))\n",
    "\n",
    "print(mean_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.93366336633664\n"
     ]
    }
   ],
   "source": [
    "print(max(mean_accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
